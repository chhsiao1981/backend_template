# -*- coding: utf-8 -*-

from {{package}}.constants import *

import os
import random
import math
import uuid
import base64
import time
import ujson as json
import pytz
from calendar import timegm
import arrow
from subprocess import Popen, PIPE
import string
import re

from {{package}} import cfg


class Error(Exception):
    def __init__(self, error_code, message):
        self.error_code = error_code
        self.message = message


##########
# mongo
##########
def db_find_one_ne(db_name, key, fields=None):
    error, result = db_find_one(db_name, key, fields)

    return result


def db_find_one(db_name, key, fields=None):
    if fields is None:
        fields = {'_id': False}

    error = None
    result = {}
    try:
        result = cfg.config.get(db_name).find_one(key, projection=fields)
        if not result:
            result = {}
        result = dict(result)
    except Exception as e:
        error = Error(S_ERR, 'unable to db_find_one: db_name: %s e: %s' % (db_name, e))
        result = {}

        _db_restart_mongo(db_name, e)

    return error, result


def db_find_ne(db_name, key=None, fields=None):
    error, result = db_find(db_name, key, fields)

    return result


def db_find(db_name, key=None, fields=None):
    if fields is None:
        fields = {'_id': False}

    error_code = S_OK
    error_msg = ''

    try:
        error, db_result_it = db_find_it(db_name, key, fields)
        result = list(db_result_it)
    except Exception as e:
        error = Error(S_ERR, 'unable to db_find: db_name: %s e: %s' % (db_name, e))
        result = []

        _db_restart_mongo(db_name, e)

    return error, result


def db_find_it_ne(db_name, key=None, fields=None, with_id=False):
    error, result = db_find_it(db_name, key, fields, with_id=with_id)

    return result


def db_find_it(db_name, key=None, fields=None, with_id=False):
    if fields is None and not with_id:
        fields = {'_id': False}
        
    error = None
    result = []
    try:
        result = cfg.config.get(db_name).find(filter=key, projection=fields)
    except Exception as e:
        error = Error(S_ERR, 'unable to db_find_iter: db_name: %s key: %s' % (db_name, key))
        result = None
        _db_restart_mongo(db_name, e)

    if not result:
        result = []

    return error, result


def db_insert_ne(db_name, val):
    error, result = db_insert(db_name, val)

    return result


def db_insert(db_name, val):
    error = None
    if not val:
        error = Error(S_ERR, 'db_name: %s no val: val: %s' % (db_name, val))
        return error, {}

    result = []
    try:
        result = cfg.config.get(db_name).insert_many(val, ordered=False)
    except Exception as e:
        error = Error(S_ERR, 'unable to insert: db_name: %s e: %s' % (db_name, e))
        result = []

        _db_restart_mongo(db_name, e)

    return error, result


def db_bulk_update(db_name, update_data, is_set=True, upsert=True, multi=True):
    '''
    update_data: [{key, val}]
    '''
    error = None
    update_data = [each_data for each_data in update_data if each_data.get('key', {}) and each_data.get('val', {})]

    # cfg.logger.info('to do db_bulk_update: update_data: %s', update_data)

    return db_force_bulk_update(db_name, update_data, is_set=is_set, upsert=upsert, multi=multi)


def db_force_bulk_update(db_name, update_data, is_set, upsert, multi):
    error = None
    if is_set:
        for each_data in update_data:
            val = each_data.get('val', {})
            each_data['val'] = {'$set': val}

    result = None
    try:
        bulk = cfg.config.get(db_name).initialize_unordered_bulk_op()
        for each_data in update_data:
            key = each_data.get('key', {})
            val = each_data.get('val', {})
            if upsert and multi:
                bulk.find(key).upsert().update(val)
            elif upsert:
                # upsert only
                bulk.find(key).upsert().update_one(val)
            elif multi:
                # multi only
                bulk.find(key).update(val)
            else:
                # no upsert and no multi
                bulk.find(key).update_one(val)
        result = bulk.execute()
    except Exception as e:
        error = Error(S_ERR, 'unable to db_force_bulk_update: db_name: %s e: %s' % (db_name, e))
        cfg.logger.error(error)
        result = None

        _db_restart_mongo(db_name, e)

    return error, getattr(result, 'raw_result', {})


def db_update(db_name, key, val, is_set=True, upsert=True, multi=True):
    error = None

    if not key or not val:
        error = Error(S_ERR, 'unable to db_update: no key or val: db_name: %s' % (db_name))
        cfg.logger.error(error.message)
        return error, {}

    return db_force_update(db_name, key, val, is_set=is_set, upsert=upsert, multi=multi)


def db_force_update(db_name, key, val, is_set=True, upsert=True, multi=True):
    error = None

    if is_set:
        val = {"$set": val}

    result = None
    try:
        if not multi:
            result = cfg.config.get(db_name).update_one(key, val, upsert=upsert)
        else:
            result = cfg.config.get(db_name).update_many(key, val, upsert=upsert)
    except Exception as e:
        error = Error(S_ERR, 'unable to db_force_update: db_name: %s e: %s' % (db_name, e))
        cfg.logger.error(error.message)
        result = None

        _db_restart_mongo(db_name, e)

    return error, getattr(result, 'raw_result', {})


def db_save(db_name, doc):
    error = None

    if not doc:
        error = Error(S_ERR, 'db_save: no doc: db_name: %s' % (db_name))
        cfg.logger.error(error.message)
        return error, {}

    result = {}
    try:
        result = cfg.config.get(db_name).save(doc)
    except Exception as e:
        error = Error(S_ERR, 'unable to db_save: db_name: %s doc: %s e: %s' % (db_name, doc, e))
        cfg.logger.error(error.message)
        result = {}

        _db_restart_mongo(db_name, e)

    return error, result


def db_remove(db_name, key):
    error = None

    if not key:
        error = Error(S_ERR, 'unable to db_remove: no key: db_name: %s' % (db_name))
        cfg.logger.error(error.message)
        return error, {}

    return db_force_remove(db_name, key=key)


def db_force_remove(db_name, key=None):
    if not key:
        key = {}

    error = None

    result = None
    try:
        result = cfg.config.get(db_name).delete_many(key)
    except Exception as e:
        error = Error(S_ERR, 'unable to db_force_remove: db_name: %s key: %s e: %s' % (db_name, key, e))
        cfg.logger.error(error.message)
        result = None

        _db_restart_mongo(db_name, e)

    return error, getattr(result, 'raw_result', {})


def db_distinct(db_name, distinct_key, query_key, fields=None, with_id=False):
    if fields is None and not with_id:
        fields = {'_id': False}

    error = None

    results = []
    try:
        db_result = cfg.config.get(db_name).find(query_key, projection=fields)
        results = db_result.distinct(distinct_key)
    except Exception as e:
        error = Error(S_ERR, 'unable to db_distinct: db_name: %s query_key: %s distinct_key: %s e: %s' % (db_name, query_key, distinct_key, e))
        cfg.logger.error(error.message)
        results = []

        _db_restart_mongo(db_name, e)

    return error, results


def db_set_if_not_exists(db_name, key, val, fields=None, with_id=False):
    if fields is None and not with_id:
        fields = {'_id': False}

    error = None
    result = {}
    try:
        result = cfg.config.get(db_name).find_one_and_update(key, {"$setOnInsert": val}, projection=fields, upsert=True, new=False)
    except Exception as e:
        error = Error(S_ERR, 'unable to set on insert: db_name: %s key: %s e: %s' % (db_name, key, e))
        result = {}

    if error:
        return error, {}

    if result:
        return Error(S_ERR_ALREADY_EXIST, 'already exists: db_name: %s key: %s' % (db_name, key)), result

    return None, {}


def db_find_and_modify(db_name, key, val, fields=None, with_id=False, is_set=True, upsert=True, multi=True):
    if fields is None and not with_id:
        fields = {'_id': False}

    error = None

    if is_set:
        val = {'$set': val}

    result = {}
    try:
        result = cfg.config.get(db_name).find_one_and_update(key, val, projection=fields, upsert=upsert, multi=multi)
        if not result:
            result = {}
    except Exception as e: 
        error = Error(S_ERR, 'unable to db_find_and_modify: db_name: %s key: %s val: %s e: %s' % (db_name, key, val, e))
        cfg.logger.error(error.message)
        result = {}

        _db_restart_mongo(db_name, e)

    return error, dict(result)


def db_aggregate_iter(db_name, pipe):
    error = None

    db_result = []
    try:
        db_result = cfg.config.get(db_name).aggregate(pipeline=pipe, cursor={}, allowDiskUse=True)
    except Exception as e:
        error = Error(S_ERR, 'unable to db_aggregate_iter: possibly 2.4 issue db_name: %s pipe: %s e: %s' % (db_name, pipe, e))
        cfg.logger.error(error.message)
        db_result = []

    if not error:
        return error, db_result

    try:
        db_result = cfg.config.get(db_name).aggregate(pipeline=pipe)
        db_result = db_result.get('result', [])
    except Exception as e:
        error = Error(S_ERR, 'unable to db_aggregate_iter: db_name: %s pipe: %s e: %s' % (db_name, pipe, e))
        cfg.logger.error(error.message)
        db_result = []

        _db_restart_mongo(db_name, e)

    return error, db_result


def db_aggregate(db_name, pipe):
    error = None

    error, db_result = db_aggregate_iter(db_name, pipe)
    if error:
        return error, []

    result = []
    try:
        result = list(db_result)
    except Exception as e:
        result = []
        error = Error(S_ERR, 'unable to db_aggregate: db_anme: %s pipe: %s e: %s' % (db_name, pipe, e))
        cfg.logger.error(error.message)

        _db_restart_mongo(db_name, e)

    return error, result


def db_aggregate_parse_results(db_results):
    '''
    db_aggregate_parse_result guarantee S_OK
    '''
    results_with_error = [db_aggregate_parse_result(db_result) for db_result in db_results]

    return flatten_results_with_error(results_with_error)


def db_aggregate_parse_result(db_result):
    result = {key: val for (key, val) in db_result.items() if key != '_id'}
    if db_result['_id']:
        result.update(db_result['_id'])

    return None, result


# FIXME: What is the difference between db_largest and db_largest_list?
def db_largest(db_name, key, query, group_columns=None):
    error, db_results = db_largest_list(db_name, key, query, group_columns)
    if error:
        return error, db_results

    # FIXME: the type(db_results) is dict?
    if not db_results:
        return Error(S_ERR, '[empty]'), {}

    return None, db_results


def db_largest_list(db_name, key, query, group_columns=None):
    '''
    key: key for max
    query: query
    group_columns: columns for grouping
    '''
    if not group_columns:
        group_columns = query.keys()

    group = {}
    group['max'] = {'$max': '$' + key}
    group['_id'] = {column: '$' + column for column in group_columns}
    pipe = [
        {'$match': query},
        {'$group': group},
    ]

    cfg.logger.debug('to db_aggregate: pipe: %s', pipe)
    error, results = db_aggregate(db_name, pipe)
    cfg.logger.debug('after db_aggregate: error: %s results: %s', error, results)

    if error:
        return error, []

    return None, results


def _db_restart_mongo(db_name, e):
    e_str = str(e)

    # ignore dup error
    if re.search('^E11000', e_str):
        return None

    cfg._init_mongo(db_name)

    return None


##########
# type 
##########
def _str(item, encoding='utf-8', default=''):
    if item.__class__.__name__ == 'unicode':
        try:
            result = item.encode(encoding)
        except Exception as e:
            result = default
        return result

    try:
        result = str(item)
    except Exception as e:
        result = default
    return result


def _unicode(item, encoding='utf-8', default=u''):
    if isinstance(item, unicode):
        return item

    return _str(item).decode(encoding)


def _int(item, default=0):
    if item == 'null':
        return 0

    if item == 'false':
        return 0

    if item == 'true':
        return 1

    result = default
    try:
        result = int(item)
    except Exception as e:
        # cfg.logger.error('unable to _int: item: %s, default: %s e: %s', item, default, e)
        result = default

    return result


def _float(item, default=0.0):
    if item == 'null':
        return 0.0

    if item == 'false':
        return 0.0

    if item == 'true':
        return 1.0

    result = default
    try:
        result = float(item)
    except Exception as e:
        # cfg.logger.error('unable to _float: item: %s, default: %s e: %s', item, default, e)
        result = default

    return result


def _bool(item):
    if item == 'true':
        return True
    
    if item == 'True':
        return True

    if item == True:
        return True

    if item == 'false':
        return False

    if item == 'False':
        return False

    if item == False:
        return False

    return False if not item else True


##########
# timestamp
##########
def timestamp_to_datetime(the_timestamp):
    return datetime.utcfromtimestamp(_int(the_timestamp))


def get_timestamp():
    return _int(time.time())


def get_milli_timestamp():
    return _int(time.time() * 1000.0)


def get_hr_timestamp():
    the_timestamp = get_timestamp()
    the_hr_timestamp_block = the_timestamp // 3600
    the_hr_timestamp = the_hr_timestamp_block * 3600

    return the_hr_timestamp


def timestamp_to_day_timestamp(the_timestamp):
    the_block = the_timestamp // 86400
    return the_block * 86400


##########
# http
##########
def http_multipost(the_url_data, timeout=HTTP_TIMEOUT, cookies=None, headers=None):
    '''
    the_url_data: {the_url: data_by_url}
    return: error, {the_url: (each_error, content)}
    '''
    error = None

    the_url_data_list = the_url_data.items()

    error, result_list = http_multipost_list(the_url_data_list, timeout=timeout, cookies=cookies, headers=headers)
    if error:
        return error, {}

    result = {each_result[0]: each_result[1] for each_result in result_list}

    return None, result


def http_multipost_list(the_url_data, timeout=HTTP_TIMEOUT, cookies=None, headers=None):
    '''
    the_url_data: [(the_url, data_by_url)]
    return: error, [(the_url, (each_error, content))]
    '''
    error = None

    cfg.logger.warning('to post: the_url_data: %s', the_url_data)

    rs = (grequests.post(each_url_data[0], data=each_url_data[1], timeout=timeout, cookies=cookies, headers=headers) for each_url_data in the_url_data)
    result_map = grequests.map(rs, exception_handler=http_exception_handler)

    result = []
    try:
        result_map_content = map(_grequest_get_content, result_map)
        result = [(each_url_data[0], result_map_content[idx]) for (idx, each_url_data) in enumerate(the_url_data)]
    except Exception as e:
        the_urls = [each_url_data[0] for each_url_data in the_url_data]
        error = Error(S_ERR, 'unable to http_multipost: the_urls: %s e: %s' % (the_urls, e))
        result = []

    return error, result


def http_multiget(the_urls, params='', timeout=HTTP_TIMEOUT, cookies=None, headers=None):
    '''
    the_urls: [the_url]
    return: error, {url: (each_error, content)}
    '''
    error = None

    cfg.logger.warning('to grequests: the_urls: %s params: %s cookies: %s', the_urls, params, cookies)

    rs = (grequests.get(u, params=params, timeout=timeout, cookies=cookies, headers=headers) for u in the_urls)
    result_map = grequests.map(rs, exception_handler=http_exception_handler)

    result = {}
    try:
        result_map_content = map(_grequest_get_content, result_map)
        result = {the_url: result_map_content[idx] for (idx, the_url) in enumerate(the_urls)}
    except Exception as e:
        error = Error(S_ERR, 'unable to http_multiget: the_urls: %s e: %s' % (the_urls, e))
        cfg.logger.error(error.message)
        result = {}

    return error, result


def http_exception_handler(request, e):
    cfg.logger.error('url: %s e: %s', request.url, e)
    return e


def _grequest_get_content(result):
    '''
    check http_multiget
    '''
    if not isinstance(result, Response):  # requests.Response
        return Error(S_ERR, 'not response'), ''

    if result.status_code >= 400:
        return Error(S_ERR, 'status_code: %s' % (result.status_code)), ''

    return None, result.content


def send_requests(all_machines, path, params, method, timeout=HTTP_TIMEOUT, cookies=None, headers=None):
    '''
    1. mapping from machine to url
    2. do parallel requests with url
    3. results: error, {machine: (each_error, data)}
    '''
    the_urls_dict = {machine: machine + path for machine in all_machines}
    the_urls_list = the_urls_dict.values()

    error, data = _send_requests_list(the_urls_list, params, method, timeout, cookies, headers)
    if error:
        return error, {}

    # data: {the_url: (each_error, content)}

    results = {machine: _parse_send_requests_data(data.get(the_url, None)) for machine, the_url in the_urls_dict.items()}

    return None, results


def send_requests_with_different_params(the_url_data, timeout=HTTP_TIMEOUT, cookies=None):
    error, result = http_multipost(the_url_data, timeout, cookies)
    if error:
        return error, {}

    return None, {machine: _parse_send_requests_data(data) for machine, data in result.items()}


def _send_requests_list(the_urls_list, params, method, timeout, cookies, headers):
    '''
    return: error, {the_url: (each_error, content)}
    '''
    if method == 'POST':
        the_url_data = {the_url: params for the_url in the_urls_list}
        return http_multipost(the_url_data, timeout, cookies, headers=headers)

    else:
        return http_multiget(the_urls_list, params, timeout, cookies, headers=headers)


def _parse_send_requests_data(data):
    if not data:
        return Error(S_ERR, '[None]'), {}

    error, content = data
    if error:
        return error, {}

    result = json_loads_ne(content)

    return None, result


##########
# json
##########
def json_dumps_ne(json_struct, default='', indent=0, sort_keys=False):
    error, result = json_dumps(json_struct, default, indent, sort_keys)

    return result


def json_dumps(json_struct, default='', indent=0, sort_keys=False):
    error = None
    result = ''
    try:
        result = json.dumps(json_struct, indent=indent)
    except Exception as e:
        error = Error(S_ERR, 'unable to json_dumps: json_struct: %s e: %s' % (json_struct, e))
        result = default

    return error, result


def json_loads_ne(json_str, default=None):
    error, result = json_loads(json_str, default)

    return result


def json_loads(json_str, default=None):
    if default is None:
        default = {}

    error = None
    result = default
    try:
        result = json.loads(json_str)
    except Exception as e:
        error = Error(S_ERR, 'unable to json_loads: json_str: %s e: %s' % (json_str, e))
        result = default

    return error, result


##########
# sys
##########
def makedirs(dir_name):
    error = None
    try:
        os.makedirs(dir_name)
    except Exception as e:
        if e.errno not in [errno.EEXIST]: # dir already exists
            error = Error(S_ERR, 'unable to makedirs: dir_name: %s e: %s' % (dir_name, e))
            cfg.logger.error(error.message)

    return error


def process_cmd(cmd, is_stdout=True, is_stderr=True, is_wait=True):
    error = None
    output_content = ''
    output_stderr = ''
    process = None

    the_stdout = PIPE if is_stdout else None
    the_stderr = PIPE if is_stderr else None
    try:
        process = Popen(cmd, stdout=the_stdout, stderr=the_stderr)

        if is_wait:
            (output_content, output_stderr) = process.communicate()
    except Exception as e:
        error = Error(S_ERR, 'unable to process cmd: cmd: %s e: %s' % (cmd, e))
        process = None
        output_content = ''
        output_stderr = ''

    return error, (process, output_content, output_stderr)


##########
# misc
##########
def gen_random_string(length=40):
    return base64.urlsafe_b64encode(str(uuid.uuid4().bytes))[:22]
